{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending Topics\n",
    "\n",
    "In class, we started to talk a bit about \"trends.\" What do we think it means for something to trend? For a trend to sweep across the nation or around the globe? Can we say something is trendy or in fashion? Or are we talking about trendsetting?  \n",
    "\n",
    "In social media platforms, trending is often reduced to popularity - a topic is being discussed at some time, in some region, perhaps among a certain community of people. So there is an implicit assumption that a trend is bigger than you and your posts, perhaps bigger than your city, but is something that is characteristic of a \"global conversation\". It's \"what's happening.\"<br><br>\n",
    "\n",
    "<img src=\"https://github.com/computationaljournalism/columbia2018/raw/master/images/tw.jpg\" style=\"width: 65%; border: #000000 1px outset;\">\n",
    "<br><br>\n",
    "\n",
    "There are **so** many questions about trends and how they are implemented on the various social media platforms. Today we are going to bring out some of the ways the idea of a trend has been made computational, and then we'll explore a little bit what trending looks like. To start us off, we can use a web site called [TrendsMap](http://trendsmap.com). \n",
    "\n",
    "This is a service that collects trends from Twitter, divided by geography. Here, for example, is a map of our area...\n",
    "<br><br>\n",
    "<img src=\"https://github.com/computationaljournalism/columbia2018/raw/master/images/tr0.jpg\" style=\"width: 65%; border: #000000 1px outset;\"/>\n",
    "<br><br>\n",
    "... followed by an overlay of the trends being discussed in the region. Notice that in the interface a trending topic can be a person or a hashtag or a collection of words.\n",
    "<br><br>\n",
    "<img src=\"https://github.com/computationaljournalism/columbia2018/raw/master/images/tr1.jpg\" style=\"width: 65%; border: #000000 1px outset;\"/>\n",
    "<br><br>\n",
    "If you toy around with the interface a little you will see all the places that they collect trends for. How are these determined? And how are trends being localized?\n",
    "<br><br>\n",
    "<img src=\"https://github.com/computationaljournalism/columbia2018/raw/master/images/tr3.jpg\" style=\"width: 65%; border: #000000 1px outset;\"/>\n",
    "<br><br>\n",
    "As an aside, when you sign up for Trendsmap, you authorize their application to access your Twitter account. Why might that be? And look carefully at what you've authorized them to do. What do you think of that?\n",
    "<br><br>\n",
    "<img src=\"https://github.com/computationaljournalism/columbia2018/raw/master/images/capture.jpg\" style=\"width: 65%; border: #000000 1px outset;\"/>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A warm up**\n",
    "\n",
    "We spent some time in the last couple notebooks looking at Twitter and its API as well as data around a particular hashtag `#LearnToCode`, the idea being that if something becomes a trending topic then it is \"what's happening.\" It is what Twitter (and by extension, some will assume) the country is thinking. \n",
    "\n",
    "So, let's start with the Twitter Trending API. We will then step it up a bit and tap into Twitter as a source of realtime information using their Streaming API to search for new tweets that contain keywors we want, or are from a particular place, or were posted by a particular person or group.\n",
    "\n",
    "We start where we ended last time - by getting our Twitter API initialized. Again, we are going to use Tweepy to make our requests. You can [read about Tweepy and its documentation here](http://docs.tweepy.org/en/v3.5.0/api.html) and specifically investigate how to access Twitter's trends [here](http://docs.tweepy.org/en/v3.5.0/api.html#trends-methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab your keys from a previous notebook or https://apps.twitter.com\n",
    "\n",
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "ACCESS_TOKEN_SECRET = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we can make Twitter API calls, we need to initialize a few things...\n",
    "from tweepy import OAuthHandler, API\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter has a few Trends-related APIs including one that allows you to see which locations have Trending data.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://developer.twitter.com/en/docs/trends/locations-with-trending-topics/api-reference/get-trends-available\n",
    "\n",
    "Below, we use a simple Tweepy method to list the different locations for which Twitter computes trends. We have seen a few in Trendsmap, but what's the full list look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the trends locations\n",
    "# https://dev.twitter.com/rest/reference/get/trends/available\n",
    "\n",
    "avail_locations = api.trends_available()\n",
    "\n",
    "print(type(avail_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list! So each entry is a place for which Twitter computes trending topics. How many places are there? And let's look at a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(avail_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avail_locations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avail_locations[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so we have used Tweepy again to invoke the web service, the API, to ask Twitter for data. Tweepy has scooped up that data and formatted it for you, putting each location as an element in a list. So, what does each location from Tweepy look like in terms of Python data objects? What kind of \"thing\" is each location? \n",
    "\n",
    "Yes! A dictionary. So, for each one, how would we select just the country name? The location name? Copy the code from above and instead of printing out the entire location, choose just one entry to print from each of the dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OK, wait!** Trying to decipher python dictionaries printed to the notebook can be painful. Here is a very simple trick to \"pretty print\" them. Use this method to print out dictionaries, lists, lists of dictionaries... pretty much anything! It makes it so much easier to look at data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty print to the rescue! And yes, the function name is pprint\n",
    "# and it is in a package named pprint. Just keep straight that we have\n",
    "# imported a handy function called pprint that we can now apply to \n",
    "# just about any object\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(avail_locations[40],indent=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or look at the entire list of 467 places..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(avail_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the entries (the \"keys\") in these dictionaries are self-explanatory and some you have to go to the documentation. In particular, there seems to be an ID associated with each place. These are `woeid`'s which stand for \"where on earth\" id. You can [read about their use in Twitter here](https://blog.twitter.com/engineering/en_us/a/2010/woeids-in-twitters-trends.html\n",
    ").\n",
    "\n",
    "<br><br>\n",
    "<img src=\"https://github.com/computationaljournalism/columbia2018/raw/master/images/wo.jpg\" style=\"width: 65%; border: #000000 1px outset;\"/>\n",
    "<br><br>\n",
    "\n",
    "Now...let's get the current trends for New York. We use the `trends_place` API and pass the `woeid` (\"where on earth\" id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trends for New York\n",
    "\n",
    "woeid = 2459115\n",
    "ny_trends = api.trends_place(woeid)\n",
    "\n",
    "print(type(ny_trends))\n",
    "print(len(ny_trends))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the result is a list with a single object stored in it (length is 1). Inside that one object you will find `trends` which is a list of dictionaries, one dictionary entry for each trend. \n",
    "\n",
    "**Your turn:** Use `pprint` to print out the whole object and write out the subsetting to return the dictionary called `trends`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ny_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to subset out the `trends` list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside: Connection to Pandas**\n",
    "\n",
    "Remember that we were able to think of a table as a list of lists, a dictionary of lists or a list of dictionaries? Well, the last structure is precisely what we have here. So recall we can use a Pandas method `DataFrame()` to create a table from these trends.\n",
    "\n",
    "Remember from the printout above, however, that our trends data is represented as a list with a single entry and that entry is a dictionary. Inside the dictionary you will see the key `trends`. That key is the one we want as it points to the list of dictionaries, each entry being a trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "ny = DataFrame(ny_trends[0][\"trends\"])\n",
    "\n",
    "# now look at the data frame we've made. what do you see?\n",
    "ny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice thing about a DataFrame is that we can save it as a CSV. So we can write it out and the later use `read_csv` if we want to work with a previous set of trends. Here's how we'd save the `ny` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny.to_csv(\"ny_trends.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Searching**\n",
    "\n",
    "If you wanted to sample something of the discussion around a topic that's trending, you can use the `query` field in the trends object to post a search to Twitter. We did this last time, but here it is again. We are looking backwards in time, from \"now\" back, finding tweets that contain our query, our trending topic. \n",
    "\n",
    "In lecture we will teach you how to listen to the stream in realtime, pulling tweets as they happen. But for now, let's see what the conversation around \"Warren2020\" is.\n",
    "\n",
    "We are going to use a loop here... remember loops from the end of our last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = api.search(\"warren2020\")\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)\n",
    "    print(\"====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that under our belt, we are going to start looking at what goes into computing a trending algorithm. We've already talked through some of the concepts, but now let's see how they get turned into something that can be implemented \"at scale,\" something computable.\n",
    "\n",
    "### Trending Algorithms: An Introduction\n",
    "\n",
    "OK so now that we see how to pull trends from Twitter, let's talk a bit more about what goes into computing them. Here's the flow of the next couple of notebooks on **trending topics**: \n",
    "\n",
    "> We will start with some [introductory](#Introduction) questions that focus on how and where trends come from? Or who decides what's on the trending topic list? It is important to understand these factors before we embark on parsing and finding patterns in data about computed trends from Twitter. This is fundamental to any data science analysis - the incentives and procedures through which the data source generates and publishes data can often give us significant knowledge about how to interrogate it. \n",
    "\n",
    ">Following that, we will explore some real [datasets](#Data) of trends collected from  Twitter over the last couple of days (using code similar to what we exhibited in the cells above). This will give you hands-on experience analyzing trends, assessing their patterns and rhythms. On Thursday, we will flip things around and you will be asked to come up with trending algorithms.\n",
    "\n",
    ">The next section will be [methods](#Methods), where we will study some metrics that help **quantify features in the trend signal**. Example features include how long a trend lasted in some location, or how many geolocations it spread to etc. Note it isn't necessary that these features will reveal something \"interesting\" about the trend. The idea of this exercise is to help you calibrate your thinking about trends as a signal of social attention. In other words, assuming trends were a signal of \"attention\", what metrics can be used to compare to trends? \n",
    "\n",
    ">Finally, we will [discuss](#Discussion) more general readings about trending topics.\n",
    "\n",
    "Due to the incredible collection of images, status updates and other content that social platforms see everyday, Trending Topics are usually determined by an \"algorithm\" (a computer program or a set of guidelines for humans to follow... or a mixture). The role of the algorithm is to collect a substantial chunk of data generated on the social media site and strive to find **words/or phrases that occur more frequently than others, or words that are being produced with high \"velocity\"**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Trending topics are determined by an algorithm measuring velocity of Tweets about a topic, not overall popularity: <a href=\"https://t.co/8gJJOT3gCw\">https://t.co/8gJJOT3gCw</a></p>&mdash; Policy (@policy) <a href=\"https://twitter.com/policy/status/742642510862950400\">June 14, 2016</a></blockquote>\n",
       "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Trending topics are determined by an algorithm measuring velocity of Tweets about a topic, not overall popularity: <a href=\"https://t.co/8gJJOT3gCw\">https://t.co/8gJJOT3gCw</a></p>&mdash; Policy (@policy) <a href=\"https://twitter.com/policy/status/742642510862950400\">June 14, 2016</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at how Twitter describes why things trend. Is it any wonder that people still complain when their topics or interests fail to trend? Let's dig a bit deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">WHY is this trending?<br>It&#39;s not a Trump issue.  <br>It&#39;s a <a href=\"https://twitter.com/hashtag/SchumerShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#SchumerShutdown</a><br>It&#39;s a Democrat shutdown<br>It&#39;s a RINO shutdown<br>Let&#39;s get this cleared up right here, right now. <a href=\"https://t.co/2DzbpcfjV9\">pic.twitter.com/2DzbpcfjV9</a></p>&mdash; PENNSYLVANIA 4 TRUMP (@TRUTH_USA_2016) <a href=\"https://twitter.com/TRUTH_USA_2016/status/954692394754158592?ref_src=twsrc%5Etfw\">January 20, 2018</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">WHY is this trending?<br>It&#39;s not a Trump issue.  <br>It&#39;s a <a href=\"https://twitter.com/hashtag/SchumerShutdown?src=hash&amp;ref_src=twsrc%5Etfw\">#SchumerShutdown</a><br>It&#39;s a Democrat shutdown<br>It&#39;s a RINO shutdown<br>Let&#39;s get this cleared up right here, right now. <a href=\"https://t.co/2DzbpcfjV9\">pic.twitter.com/2DzbpcfjV9</a></p>&mdash; PENNSYLVANIA 4 TRUMP (@TRUTH_USA_2016) <a href=\"https://twitter.com/TRUTH_USA_2016/status/954692394754158592?ref_src=twsrc%5Etfw\">January 20, 2018</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the term \"velocity\" mean here? \n",
    "\n",
    "Intuitively, one might expect that a trend must be both popular and timely. That is, it must be talked about by a large number of people. Great. Timely? How do we capture that? In Twitter's case, not only does a topic have to capture the attention of a large number of people, but  this group has to represent **a significant jump in the number of people who have previously mentioned the topic.** \n",
    "\n",
    "As an example, the President is discussed often on social media sites, but we only want to flag him as a trending topic if the conversation about him spikes quickly, perhaps due to the State of the Union address, a \"rough languaged\" tweet, a press conference, or the signing of an executive order.\n",
    "\n",
    "Velocity is a measure of this real time surge in discussion about a topic. A simplistic way to compute velocity is to examine a graph of tweets (or FB messages) on a topic occurring in 5- or 10-minute windows (the window size is a \"parameter\" that needs to be specified). The velocity of a topic is the increase in the number of mentions of a topic from one time period to the next. (We saw graphs like this for #schumershutdown and #twittershutdown.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, remember when the power went out during the SuperBowl of 2013?\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">All the lights are out!! It’s pandemonium!! Thank god we have out Beyonce finger lights! <a href=\"http://t.co/JxUKr27i\">pic.twitter.com/JxUKr27i</a></p>&mdash; Neil Patrick Harris (@ActuallyNPH) <a href=\"https://twitter.com/ActuallyNPH/status/298245477042900992\">February 4, 2013</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "Here is a chart comparing two topics, \"superbowl\" and \"power\" that evening. \n",
    "\n",
    "<img src=\"http://www.socialflow.com/wp-content/uploads/2013/02/power_superbowl.jpg\" style=\"width: 80%;\"/>\n",
    "\n",
    "While both have peaks in this plot, the \"power\" outage clearly spikes once the lights go out in the stadium. Its velocity or jump at this point is enormous and eclipses the superbowl itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to talk about several things to consider when designing a trending algorithm. \n",
    "\n",
    "**Sampling**\n",
    "\n",
    "Trending algorithms often begin by creating a **sample** of tweets or other messages on a social network. Why do we want to work with  a subset of these messages, why not the whole thing you ask? Well, for one, the data might simply be too big to analyze quickly. In this case, some form of random sampling would help reduce the size of the data, but hopefully preserve the important patterns. As we have seen, Twitter, for example, offers users a random sample of tweets from their API.\n",
    "\n",
    "Also, depending on your notion of a trend, we might want to identify patterns in certain groups or communities within a social network. This means creating a sample of data from just these members, possibly using statistical sampling again if the number is too large. \n",
    "\n",
    "For example, Twitter computes trending topics for 400 places around the world. Some places are cities, some are entire countries and then there is a category for worldwide trending topics. By forming geography-based samples, we can ask what are the trending topics in Austin? In New York City? In the United States? Facebook also computes trends for geographic regions, but the restrict this to 5 zones -- Canada, the USA, India, Great Britian, and Australia. As we noted in class, this captures a large chunk of the English speaking world. \n",
    "\n",
    "So sampling, being the first phase of the trend algorithm, plays a critical role in specifying what trends you are after. For example, if you sample all Facebook messages originating from India vs. those originating from the USA, then there is bound to be significant difference in the trending topic list, because the status updates from these countries would almost certainly be different. This is true unless there is a global event that captures the attention of both nations simulateneously. \n",
    "\n",
    "**Personalization**\n",
    "\n",
    "Beyond forming trends from data on broad groups of users, Twitter (and Facebook until last year) further personalize trends to you and your corner of the network. These personalized trends can be based on \n",
    "1. Your location,\n",
    "2. The people you follow or are friends with, and \n",
    "3. Your interests: Pages you follow or things you LIKE/RT \n",
    "Twitter calls this sort of personalization \"Tailored Trends\" which is \"on\" by default. You can change this defalut and instead receive trending topics from any of their geographic lists. Your Facebook trending list is also personalized by default, but more importantly, it is *not possible* to retrieve a list of trends for the five Facebook zones in Facebook's interface. \n",
    "\n",
    "This means that on Twitter, you can see what's trending in Paris even if you live in Boston. On Facebook, you cannot see what's trending in Australia unless you live there. \n",
    "\n",
    "(Luckily for us, the services that Facebook offers to its developers give us access to the list of Facebook trends for their 5 zones. These will be the subject of our initial data work.)\n",
    "\n",
    "**Influencers**\n",
    "\n",
    "Trends might also be defined by *who* is talking about a given topic. If people are \"high profile\" -- having a large number of followers or perhaps always earning a large number of LIKEs/RTs -- perhaps their interests should be weighted more heavily.\n",
    "\n",
    "While this framing focuses on the high end, it might also be worth looking at the low profile users, perhaps as an indication of accounts that are \"fake.\" We might consider downweighting messages from these users.\n",
    "\n",
    "**Trend Propagation**\n",
    "\n",
    "So the next obvious question is: why does a trend start in one place and spread all over the network? To understand this, we must delve a bit deeper. A sequence of activity resembles what we call time series data. Activity in a social network can be tracked in three levels: (1) Micro, (2) Meso and (3) Macro. \n",
    "\n",
    "* Micro: You tweet or RT something\n",
    "* Meso: All the people in Washington DC tweet/RT something\n",
    "* Macro: The entire network activity\n",
    "\n",
    "Meso signals resemble time series data generated from activity of a collection of users. We do not know exactly how such activity correlates with one other, but most previous research hint at information cascades as one reason.\n",
    "\n",
    "**Information cascades** resemble a mathematical system where each node will make a decision of whether to forward the message/information or not based on its previous experience (is this a influential person) and the current signal information (is this tweet good enough to RT). In general, the *n*th agent considers the decisions of the previous *n-1* agents, and his/her own signal. He/she then makes a decision based on some reasoning to determine the most rational choice. The result is a set of activities on information propagating from node to node. \n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*7988kEm4d2hDZdCpQoMGiQ.png\">\n",
    "\n",
    "Because meso signals are generated from micro signal (individual) activity and individual activity is influenced by network topology (who you follow and who follows you), the trend signal is indirectly caused by information dynamics governed by network topology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Attention Signal**\n",
    "\n",
    "Thus, the **trending topic over time is a SIGNAL** - a signal for what has captured the attention of a particular demographic (i.e. in a geo-location or within a community). Plotting such topic signals can often reveal interesting facts about information diffusion. \n",
    "\n",
    "For example, lets look at the trending topic '#Ferguson' in various US cities. \n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*NXer4xgyr9qFEnUEjuIFJA.gif\">\n",
    "\n",
    "Here, the X-axis represents a fixed duration of time from when the trend was first seen in St. Louis. Y-axis represents the score of the trend in the trending topic list. (A score of 10 represents rank 1)\n",
    "\n",
    "** Some Useful Introductory Data Reads**\n",
    "\n",
    "| Article | Description |\n",
    "| ------ | ----------- |\n",
    "|1. [FB Newsroom Trending Topics Guideline (Historical)](https://fbnewsroomus.files.wordpress.com/2016/05/full-trending-review-guidelines.pdf)   |  How your news gets to be on the Trending Topic List |\n",
    "|2. [The Digital Flames of Ferguson](https://medium.com/i-data/the-digital-flames-of-ferguson-87c4eb9aaae4#.5cuci5dm0) | Quantifying how news spreads from location to location using Twitter trends. |\n",
    "|3. [#TrumpWon: Trend vs. Reality](https://medium.com/i-data/trumpwon-trend-vs-reality-16cec3badd60#.lspl71ll7)   | Our reality is decided by what we pay attention to. |\n",
    "|4. [Hong Kong, the World and Facebook Trends](https://medium.com/i-data/hong-kong-the-world-and-facebook-trends-28331ee8f2d1#.60t0s8k3j)   | A product's user Interface design can affect what becomes a trend|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trends in Twitter###\n",
    "\n",
    "Now that we know how to pull trends data from Twitter every 15 minutes, let's look at what you get. We collected trends so as to cover the State of the Union address. You can [download the data](https://www.dropbox.com/s/48zi1qrmjocbf72/trends.csv?dl=0) and place it in the same folder as this notebook.\n",
    "\n",
    "The file is a CSV and we'll read it in via the `pandas` function `read_csv()`. We will also use `set_option()` to display 100 rows rather than the usual 30. Remember `set_option` is a way to configure `pandas` output, like the number of characters displayed in each cell or the number of columns or rows in a table. \n",
    "\n",
    "The informative and useful (yes, both!) documentation on the options available are [given here](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html). You should start getting used to the look of documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, set_option\n",
    "set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = read_csv('trends.csv')\n",
    "trends.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, nearly 1M rows. Gosh! Let's look at the first few lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trends.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `rank` gives the order of the trends pulled from the API and the `epoch` represents the 15-minute period during which the trends were collected by YMY (Young Mike Young). We then have the `name` of the trend and its `tweet_volume`. It appears to me that this count represents the use of the `name` globally, not the number of tweets specific to Algeria, say, that include the `name`. We then record the `place` and its `woeid`.\n",
    "\n",
    "My understanding of the `created_at` column is that Twitter generates trends on a regular basis for places and this time represents when the trends were computed. (Although, again, they are fairly silent about just what goes into that computation.)\n",
    "\n",
    "The data are sorted first by city and then by time, running from oldest to newest topic. The display of the first 100 lines shows this structure clearly. After 50 trends from midnight on February 2 (UTC), we jump to the trends from 15 minutes after midnight in Algeria.\n",
    "\n",
    "We can look at the first and the last entries to get a sense of the period of our data collection from Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, data were collected from Twitter from midnight UTC on February 5 (about 7pm February 4 NYC time) until February 6 at 2:45 in the afternoon UTC (about 9:45am NYC time February 6). So we have 39 hours or so of data collection. We see that there are 126 unique places (countries, and then cities in the US) and we can look at how many trends we have from each..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends[\"place\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have more to say about subsetting Data Frames and the objects that are created shortly. For now, they are columns of data and when you have a qualitative variable, the cleaneast summary is just a tabulation of its values.\n",
    "\n",
    "For qualitiative data like `tweet_volume`, we might look at the smallest and largest values or see something of the overall distribution... Here we just sort the data, looking at 1000 values. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends.sort_values(\"tweet_volume\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that at the \"low end\" of the distribution, we have trend names with missing values for trending topics. I am honestly not clear what these mean. Any ideas? How would we investigate this?\n",
    "\n",
    "Now, a Pandas Data Frame can hold a number of different kinds of data. Numbers, characters, and ohter kinds of Python objects. Because text data are often stored in columns of data frames, Pandas has provided access to a special set of string methods. They are accessed through the `.str` object of the text column. So here we are turning our `name` column to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends[\"name\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or we can test if the strings in the `names` column `contiains()` a specific pattern. Here we use the argument `case` to tell Pandas to test not just for \"sotu\" but \"SOTU\" and \"SoTU\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends[\"name\"].str.contains(\"sotu\",case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends[\"name\"].str.contains(\"sotu\",case=False).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are joining two booleans. In Pandas, we use \"&\" for `and` and \"|\" for `or`. So here are all the trends that contain \"trump\" and are from \"San Francisco\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends[trends[\"name\"].str.contains(\"trump\",case=False) & (trends[\"place\"]==\"San Francisco\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the trends in SF..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trumpsf = trends[trends[\"name\"].str.contains(\"trump\",case=False) & (trends[\"place\"]==\"San Francisco\")]\n",
    "trumpsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we count the references..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trumpsf[\"name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... perhaps making them lowercase first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trumpsf[\"name\"].str.lower().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so lets have a look at when these different terms trended. In the code below, time is on the x-axis and the name of the trend is on the y-axis. (I've made the trend lowercase so that \"Joshua Trump\" and \"joshua trump\" map to the same trend.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the good old plotly plot\n",
    "\n",
    "from plotly.plotly import iplot, sign_in\n",
    "import plotly.graph_objs as go \n",
    "\n",
    "sign_in(\"cocteautt\",\"8YLww0QuMPVQ46meAMaq\")\n",
    "\n",
    "myplot_parts = [go.Scatter(x=trumpsf[\"query_time\"],y=trumpsf[\"name\"].str.lower(),mode=\"markers\")]\n",
    "mylayout = go.Layout(autosize=False, width=800,height=400)\n",
    "myfigure = go.Figure(data = myplot_parts, layout = mylayout)\n",
    "iplot(myfigure,filename=\"trumpsf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Las Vegas (and Pandas Series)**\n",
    "\n",
    "Now, let's pick a city and look at its trends. Las Vegas is a reasonably large city. Let's look at what kinds of topics trended there. We would usually use `value_counts()` to summarize a qualitative data column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trendy = trends[ trends[\"place\"] == \"Las Vegas\" ]\n",
    "topics = trendy[\"name\"].value_counts()\n",
    "\n",
    "type(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `value_counts()` method returns a single Pandas column of data, an object of type `Series`. You can think of a `Series` as a `list`, but one that might have names attached to each entry. So our `value_counts()` `Series` has its core \"list\" data (the number of times each topic appeared in Las Vegas, say) but each data point also has a label (the topic name). \n",
    "\n",
    "So **you can subset it just like you would a list**. Here we take the first 25 most frequent topics. Remember how slices work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the names, Pandas gives you the ability to use not just row numbers (as we have been doing) but also row names (strings that describe each row rather than a number). It calls them an \"index\". So far, our index has always been just a row number. Here's our trends data, for example. \n",
    "\n",
    "The index here is the column of bold numbers that start with 0 and run through 4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get access to the index of a DataFrame or a series by referring to \".index\". It returns something that is again like a list. Here is the index for our \"topics\" Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, becaue the index is list-like, you can make a subset. Here we look at just the first 25 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = topics.index[:25]\n",
    "tops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then ask if various strings are in this (essentially) list. The operator `in` does that for for single strings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#SOTU\" in tops)\n",
    "print(\"Columbia Journalism\" in tops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and if our strings are in a Pandas DataFrame, we can use the equivalent operator `isin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trendy[\"name\"].isin(tops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `isin` operator makes us a mask that we can use to subset our Las Vegas trends data, keeping only the rows associated with the top 25 trends, say. We can then plot these top 25 in a dot chart. I've make the code for plotly a bit easier to follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the good old plotly plot\n",
    "\n",
    "from plotly.plotly import iplot, sign_in\n",
    "import plotly.graph_objs as go \n",
    "\n",
    "sign_in(\"cocteautt\",\"8YLww0QuMPVQ46meAMaq\")\n",
    "\n",
    "trendy_tops = trendy[trendy[\"name\"].isin(tops)]\n",
    "\n",
    "myplot_parts = [go.Scatter(x=trendy_tops[\"query_time\"],y=trendy_tops[\"name\"],mode=\"markers\")]\n",
    "mylayout = go.Layout(autosize=False, width=1000,height=800,margin=go.layout.Margin(l=150,r=50,b=100,t=100,pad=4))\n",
    "myfigure = go.Figure(data = myplot_parts, layout = mylayout)\n",
    "iplot(myfigure,filename=\"lasvegas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Origins of a trend -- Looking in both time and space**\n",
    "\n",
    "The origin of a trend indicates where it was initiated. The main reason origin is a fascinating features includes (1) big trends can originate in small cities and go national (2) sometimes cities have an affinity to initiate certain categories of trends, e.g., many gaming trending topics originate in SF whereas numerous fashion trending topics originate in NY. \n",
    "\n",
    "\n",
    "Let's see where else it trended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_topic = '#SOTU'\n",
    "\n",
    "trends_topic = trends[trends['name']==target_topic].sort_values(by=\"query_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the good old plotly plot\n",
    "\n",
    "myplot_parts = [go.Scatter(x=trends_topic[\"query_time\"],y=trends_topic[\"place\"],mode=\"markers\")]\n",
    "mylayout = go.Layout(autosize=False, width=1000,height=2500,margin=go.Margin(l=150,r=50,b=100,t=100,pad=4))\n",
    "myfigure = go.Figure(data = myplot_parts, layout = mylayout)\n",
    "iplot(myfigure,filename=\"mytrends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_topic.sort_values(by=\"query_time\").head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn**\n",
    "\n",
    "We began by looking at trends in Las Vegas and then moved out to various cities. We can extend this analysis in various ways. Starting with another city or the United States? Looking for less common trending topics (not the top 25 but maybe a middle 25? What else?\n",
    "\n",
    "Try!\n",
    "\n",
    "I've pulled the important code into four short steps. There's a lot of, um, pedagogy up there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load up pandas and then read in the data\n",
    "from pandas import read_csv,set_option\n",
    "\n",
    "trends = read_csv('trends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. look at one city, here \"Las Vegas\"\n",
    "trendy = trends[ trends[\"place\"] == \"Las Vegas\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. pull the top trending topics (Is the top 25 right? Too many?)\n",
    "topics = trendy[\"name\"].value_counts()\n",
    "tops = topics.index[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. prepare to plot trends from the city\n",
    "from plotly.plotly import iplot, sign_in\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "sign_in(\"cocteautt\",\"8YLww0QuMPVQ46meAMaq\")\n",
    "\n",
    "trendy_tops = trendy[trendy[\"name\"].isin(tops)]\n",
    "\n",
    "myplot_parts = [go.Scatter(x=trendy_tops[\"query_time\"],y=trendy_tops[\"name\"],mode=\"markers\")]\n",
    "mylayout = go.Layout(autosize=False, width=1000,height=800,margin=go.layout.Margin(l=150,r=50,b=100,t=100,pad=4))\n",
    "myfigure = go.Figure(data = myplot_parts, layout = mylayout)\n",
    "iplot(myfigure,filename=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Look at a single trend and plot it\n",
    "target_topic = '#TheBachelor'\n",
    "\n",
    "trends_topic = trends[trends['name']==target_topic]\n",
    "\n",
    "mydata = [go.Scatter(x=trends_topic[\"query_time\"],y=trends_topic[\"place\"],mode=\"markers\")]\n",
    "mylayout = go.Layout(autosize=False, width=1000,height=2500,margin=go.layout.Margin(l=150,r=50,b=100,t=100,pad=4))\n",
    "myfigure = go.Figure(data = mydata, layout = mylayout)\n",
    "iplot(myfigure,filename=\"bach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In homework, we will have you look at other topics like the persistence, recurrence and drift of a trend over time, as well as bias in trending algorithms. You will also have an exercise using both programmatic and manual reporting means to track trends in news sources. More to come on that!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
