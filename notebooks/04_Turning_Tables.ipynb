{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://i.kinja-img.com/gawker-media/image/upload/s--4GkTfScj--/c_scale,f_auto,fl_progressive,q_80,w_800/f174xi1inclu89xel9ea.jpg width=600>\n",
    "\n",
    "## Turning Tables ##\n",
    "\n",
    "On January 7, Axios published a \"scoop\" describing the President's daily schedule based on \"his private schedule shown to Axios.\"\n",
    "\n",
    ">[Scoop: Trump's secret, shrinking schedule](https://www.axios.com/scoop-trumps-secret-shrinking-schedule-1515364904-ab76374a-6252-4570-a804-942b3f851840.html)<br>\n",
    "President Trump is starting his official day much later than he did in the early days of his presidency, often around 11am, and holding far fewer meetings, according to copies of his private schedule shown to Axios. This is largely to meet Trump’s demands for more “Executive Time,” which almost always means TV and Twitter time alone in the residence, officials tell us.\n",
    "\n",
    "Just yesterday, Axios released [the President's complete schedule in PDF format](https://www.documentcloud.org/documents/5720284-Axios-President-Donald-Trump-Private-Schedules.html), prompting a new round of coverage in [The Guardian](https://www.theguardian.com/us-news/2019/feb/03/trump-executive-time-axios), [Vox](https://www.vox.com/policy-and-politics/2019/2/4/18210345/trump-executive-time-axios-private-schedule-leak) and elsewhere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A White House aide is weaponizing his schedules, which says a lot about how people in the White House feel about the man they work for <a href=\"https://t.co/76K7XCzwPD\">https://t.co/76K7XCzwPD</a></p>&mdash; Maggie Haberman (@maggieNYT) <a href=\"https://twitter.com/maggieNYT/status/1092194637958258690?ref_src=twsrc%5Etfw\">February 3, 2019</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axios published the calendar in PDF. Is that a good or a bad thing?\n",
    "\n",
    "*PDF (the Portable Document Format)* is really good for representing documents -- creating a standard like this was a huge deal when PDF was introduced. It began as a proprietary format developed by Adobe, but was released as an open standard in 2008. At first, it was a way to format text and images that was independent of the authoring application, the kind of operating system you were using or the hardware you had. In time, the specification included \"rich media\" like video, and now it even incorporates a seurity model with encryption and digital signatures. But at the end of the day, information that is encoded in a PDF is designed to be read by humans. The fixed format is analogous to having a paper docment. \n",
    "\n",
    "For whatever reason, it often becomes a vehicle for publishing data -- which isn't such a good thing. We have all seen pages of tables represented as PDF documents, and in such cases you start to see the format's weaknesses. Extracting data from a PDF will depend, first, on the kind of PDF it is. If you can \"select\" text from the document, you're in luck. There are several tools to help you get reasonably close to the data. If, on the other hand, your pages are essentially images, well, then you have to rely on \"optical character recognition\" programs that cluster black and white pixels, say, into letters and words and sentences.\n",
    "\n",
    "In the case of the Axios PDF's, each schedule entry is represented by a few lines of text that we might want to perform analysis on. **Let's start by reading the text and describing what questions you would like to answer about this document (and, in turn, how the President spends his time), and what data we might want to extract from the PDF for each event in his diary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axios has made the data available in a CSV (comma-separated values) format, meaning a table or spreadsheet. You can see [the table here](https://docs.google.com/spreadsheets/d/1oITCuVsYdhNXtY7GElLelsrbjRRIPJ1ce-_v-8J1X_A/edit#gid=0). Have a look. Each row represents one of Trump's diary entries and each column represents a certain \"measurement\" or observation about each event. \n",
    "\n",
    "Did they reduce each verbal description of the events in the President's schedule into table entries the way you'd hoped? Anything missing?\n",
    "\n",
    "Download the table as \"CSV\" and save it in the same folder as your notebook.\n",
    "\n",
    "**Relation to built-in types**\n",
    "\n",
    "The table we have downloaded is in a special form. Each row represents a unit of observation (in this case, a diary entry, but last time each row was a tweet contributing to the \"learn to code\" meme) and each column is a kind of measurement taken on the different object under study. So for the diary entries our \"measurements\" have to do with start time and end time and duration of meetings, along with location and attendees. Neither dictionaries nor lists completely capture this tabular structure. We have seen attempts at it. \n",
    "\n",
    "1. Dictionary of lists. Here's one way to structure the first five rows of the table. Each column is an element of a dictionary, where the `keys` are the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"week\":[1,1,1,1,1],\n",
    "  \"date\":[\"2018-11-07\",\"2018-11-07\",\"2018-11-07\",\"2018-11-07\",\"2018-11-07\"],\n",
    "  \"time_start\":[\"08:00\",\"11:00\",\"11:30\",\"12:30\",\"13:30\"],\n",
    "  \"time_end\":[\"11:00\",\"11:30\",\"12:30\",\"13:30\",\"17:00\"],\n",
    "  \"duration\":[3,0.5,1,1,3.5],\n",
    "  \"listed_title\":[\"Executive time\",\"Meeting with the chief of staff\",\"Executive time\",\"Lunch\",\"Executive time\"],\n",
    "  \"top_category\":[\"executive_time\",\"meeting\",\"executive_time\",\"lunch\",\"executive_time\"],\n",
    "  \"listed_location\":[\"Oval office\",\"Oval office\",\"Oval office\",\"Private dining room\",\"Oval office\"],\n",
    "  \"listed_project_officer\":[0,0,0,0,0],\n",
    "  \"detail_category\":[\"executive_time\",\"cos_meeting\",\"executive_time\",\"solo_lunch\",\"executive_time\"]\n",
    "}\n",
    "\n",
    "# Write some code to extract the duration of the third meeting of the day\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Lists of dictionaries. The rows are now organized as dictionaries and each row is an element in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"08:00\",\"time_end\":\"11:00\",\"duration\":3,\"listed_title\":\"Executive time\",\"top_category\":\"executive_time\",\"listed_location\":\"Oval office\",\"listed_project_officer\":null,\"detail_category\":\"executive_time\"},\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"11:00\",\"time_end\":\"11:30\",\"duration\":0.5,\"listed_title\":\"Meeting with the chief of staff\",\"top_category\":\"meeting\",\"listed_location\":\"Oval office\",\"listed_project_officer\":null,\"detail_category\":\"cos_meeting\"},\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"11:30\",\"time_end\":\"12:30\",\"duration\":1,\"listed_title\":\"Executive time\",\"top_category\":\"executive_time\",\"listed_location\":\"Oval office\",\"listed_project_officer\":null,\"detail_category\":\"executive_time\"},\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"12:30\",\"time_end\":\"13:30\",\"duration\":1,\"listed_title\":\"Lunch\",\"top_category\":\"lunch\",\"listed_location\":\"Private dining room\",\"listed_project_officer\":null,\"detail_category\":\"solo_lunch\"},\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"13:30\",\"time_end\":\"17:00\",\"duration\":3.5,\"listed_title\":\"Executive time\",\"top_category\":\"executive_time\",\"listed_location\":\"Oval office\",\"listed_project_officer\":null,\"detail_category\":\"executive_time\"}\n",
    "]\n",
    "\n",
    "# Write code to extract the start and end times of the second event of the day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Mr. Data Converter, we see that this is yet another way to organize data in a table using the built-in objects. We saw it in our last class. \n",
    "\n",
    "3. A list of lists. In Mr. Data Converter this is called JSON - Row Arrays. This one has the slight disadvantge in that the column names are lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "  [1,\"2018-11-07\",\"08:00\",\"11:00\",3,\"Executive time\",\"executive_time\",\"Oval office\",0,\"executive_time\"],\n",
    "  [1,\"2018-11-07\",\"11:00\",\"11:30\",0.5,\"Meeting with the chief of staff\",\"meeting\",\"Oval office\",0,\"cos_meeting\"],\n",
    "  [1,\"2018-11-07\",\"11:30\",\"12:30\",1,\"Executive time\",\"executive_time\",\"Oval office\",0,\"executive_time\"],\n",
    "  [1,\"2018-11-07\",\"12:30\",\"13:30\",1,\"Lunch\",\"lunch\",\"Private dining room\",0,\"solo_lunch\"],\n",
    "  [1,\"2018-11-07\",\"13:30\",\"17:00\",3.5,\"Executive time\",\"executive_time\",\"Oval office\",0,\"executive_time\"]\n",
    "]\n",
    "\n",
    "# Write some code to extract the 'listed_title' of the second event.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tradeoffs between the different formats are dispayed beautifully in Shan Carter's [Mr. Data Converter](https://shancarter.github.io/mr-data-converter/). With this tool, Shan lets you play with different formats. The three above are \"JSON - Column Arrays,\" \"JSON - Properties,\" and \"JSON - Row Arrays.\" Remember, JSON or the JavaScript Object Notation is a format for expressing data that is (essentially) the same as the built-in objects in Python -- numbers, character strings and booleans piled into lists and dictionaries. \n",
    "\n",
    "So the material we've been learning typically has variants in other languages and data formats. \n",
    "\n",
    "**Built-in support for CSV's**\n",
    "\n",
    "Python has some basic built-in support for dealing with CSVs, since it's a common task. You can, for example, read in CSV's row by row (line by line) from a CSV file, much like we did data from Trump's tweets on the first day. Remember that CSV stands for Comma Separated Values. Each line in the file is a row of data -- well, the first represents a \"header\" of column names. For each subsequent row, the elements corresponding to the different columns are separated by commas. This format is remarkably robust and you will see it often.\n",
    "\n",
    "One way to work with a CSV file in Python is through a package called `csv`. The main functions you will import are either a CSV `writer` or a CSV `reader`. Let's try the latter on the President's schedule data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# open the file\n",
    "diary_file = open(\"Axios _ President Donald Trump Private Schedules, Nov. 7, 2018 to Feb. 2, 2019 - data.csv\")\n",
    "\n",
    "# use the file to create a csv reader called diary_data\n",
    "diary_data = reader(diary_file)\n",
    "type(diary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the file row-by-row by using a global function called `next()`. This is a nice example of languages evolving. It used to be that `next()` was a method of the CSV reader object and so we would call `dairy_data.next()` to walk through the data in the schedule file. But there are enough objects that you \"loop\" or iterate over, taking one element after the next sequentially, that in moving from Python 2 to Python 3, the `next()` function became a global like `print()` or `help()`. Languages evolve -- there is no sense that one way of doing things is the absolute best (although some approaches do seem like the worst).\n",
    "\n",
    "So, we grab rows of the CSV file using `next()` and we'll see that each row is a list -- corresponding to the third representation above, the \"list of lists.\" The first list is just the \"header\" describing what the columns mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(diary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(diary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(diary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the built-in support for CSV's is minimal. You can walk through a file and pull out one row at a time, each row being a list. The `diary_data` reader object does have one piece of data you can access, one \"attribute\" -- the line number you're on. \n",
    "\n",
    "An attribute of an object is information stored with the object that we can again access with \"dot\" notation. Because we are looking up information and not computing something (like making strings lowercase, say), we don't need parentheses. \n",
    "\n",
    "So far we have read three lines from our file so we are on line 4 (which means index 3 since we start counting from 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary_data.line_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, repopen the file to start from the beginning, create a new `reader` object and print out the duration of Trump's first meeting of November 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# open the file\n",
    "diary_file = open(\"Axios _ President Donald Trump Private Schedules, Nov. 7, 2018 to Feb. 2, 2019 - data.csv\")\n",
    "\n",
    "# use the file to create a csv reader called diary_data\n",
    "diary_data = reader(diary_file)\n",
    "\n",
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Pandas DataFrame**\n",
    "\n",
    "While we can work with CSV's in this way, either via lists of lists, or lists of dictionaries, or dictionaries of lists, or as a CSV `reader`, none of these really captures the kind of functionality we are used to with a spreadsheet program. How would we sort the data according to a single column? How would we take the average duration of Trump's meetings? How would we count up how many entries are marked \"Executive Time\"? Don't get me wrong, you can do all these things, it's just painful -- having seen the basic data types, it's time to properly jump ahead to the big leagues. \n",
    "\n",
    "Enter a new object...\n",
    "\n",
    "In Python, the answer to Excel (or a popular answer) is a so-called Pandas **DataFrame**. Pandas refers to a package contributed by a Python developer who wanted to make working with tabular data easier. \n",
    "\n",
    "[You can read more about Pandas here](http://pandas.pydata.org/)\n",
    "\n",
    "[And there are simple tutorials here](http://nbviewer.jupyter.org/github/jvns/pandas-cookbook/blob/v0.1/cookbook/Chapter%201%20-%20Reading%20from%20a%20CSV.ipynb)\n",
    "\n",
    "<img src=https://covers.oreillystatic.com/images/0636920050896/cat.gif>\n",
    "\n",
    "Pandas is a **package**. It is written by [Wes McKinney](https://qz.com/1126615/the-story-of-the-most-important-tool-in-data-science/). Remember, packages are the ways in which developers can publish data, functions and a host of new objects for the community to use. Whereas the built-in objects are basic and get us pretty far, often we need something special to make our lives easier. In the case of Pandas, an object of type DataFrame will help us manipulate (compute with, make graphs of, etc) simple tabular data. \n",
    "\n",
    "We can read a CSV directly into a Data Frame with a function called, well, `read_csv()`. It lives in the `pandas` package and we import it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "diary = read_csv(\"Axios _ President Donald Trump Private Schedules, Nov. 7, 2018 to Feb. 2, 2019 - data.csv\")\n",
    "diary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see by scrolling that we list out the first and last 30 rows. If you scroll all the way down to the bottom, you'll see there are 577 rows in total. But you can get at this directly -- a DataFrame object has an attribute that stores its dimensions (number of rows and columns). It's called `shape`. \n",
    "\n",
    "Again you access attributes with the \"dot\" notation, and because we are looking up information and not computing something (like making strings lowercase, say), we don't need parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So We have 577 meetings (rows in the table) and 11 variables recorded for each. We can have a look at the \"top\" and \"bottom\" of the data set. These are printed with `head()` and `tail()`methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head()` and `tail()` methods of a DataFrame gives you five time periods from the start and end of the data (and you can give an argument to see more). It's important to look at the top and bottom of the file to check that everything looks consistent (column entries seem to mean what they should) and see how the data might be organized.\n",
    "\n",
    "Some of the primary operations we perform on tables are simple ordering of rows and \"subsetting\" either rows or columns -- identifying data that's worth a second look. Here we use the method `.sort_valeus()` to sort the rows of the data frame according to some variable. Here we take `duration`, from smallest to largest. (How would you sort in descending order of duration? Google!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diary.sort_values('duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can involve more than one column in the sort. Just include their names in a list. The method `.sort_values()` takes either a column name (string) or a list of names (list of strings). If it's a list it orders the rows by the first column name first, then by the values under the second, third and so on column names in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary.sort_values(['time_start','duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to sorting, we might want to focus our attention only on certain columns. We can select columns from a DataFrame using the same convention as with sorting. We provide either a single column name or a list of column names that we'd like to pull out from the data frame. \n",
    "\n",
    "The syntax is meant to look like that of a dictionary -- You give names, contained in square braces. So here we are keeping the `listed_title` and then the `listed_title` along with the duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[\"listed_title\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[ [\"listed_title\",\"duration\"] ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added an extra space to separate the square braces in `diary[ ]` from the square braces defining the list of column names we wanted `[\"listed_title\",\"duration\"]`. You don't need the space and you probably won't include it, but for the first time seeing it, it might help.\n",
    "\n",
    "Now, given the data from a single column, we might want to create a table of values. For example, what is the breakdown of the `listed_title` column? The method `.value_counts()` will take a column and tabulate the number of each unique entry. Here we see `Executive time` has the highest count by a long shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary['listed_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to tabulate the number of meetings per day\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pushing a little farter, we can pull out all the `listed_title` data into a single column using subsetting (with square braces and the column name)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[\"listed_title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and we can ask if they equal `Executive time` or not. This uses our comparison operator `==` but with a Data Frame, it can run down the whole column at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[\"listed_title\"] == \"Executive time\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `True` and `False` data to subset rows of the table -- here we keep just the rows where the title is \"`Executive time`\". **Keep in mind that our subsetting expressions now work in two ways.** \n",
    "\n",
    "Using `diary[ ]`, we can select columns by giving a name or list of names. With the next expression we see that if we provide a column of `True` and `False` values, the subsetting will keep just the portion of the table with `True`, or in this case, where we have `Executive time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[ diary[\"listed_title\"] == \"Executive time\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the simplest thing to do is just sum up the total duration spent in executive time. First, let's sum up the durations for the entire data frame... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[\"duration\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and then subset the data frame to just the executive time entries and form a sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_diary = diary[ diary[\"listed_title\"] == \"Executive time\" ]\n",
    "exec_diary[\"duration\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use `sum()` as we did with `followers` in our drill, but the nice thing about the method associated with the data frame column is that it removes the missing values when it forms the sum. That makes life easier. There are a few entries that have missing durations -- listed as NaN.\n",
    "\n",
    "And the headline for so many stories comes from this computation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "297/503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Wednesday, you are going to work with data from the \"learn to code\" tweets. They are stored as a CSV and we will read them in and ask you to do some things, let you try out some other things on your own. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
